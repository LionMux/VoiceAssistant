import pyaudio
import numpy as np
from faster_whisper import WhisperModel
import time


class WhisperRecognizer:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Whisper (faster-whisper)
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ë–ï–ó –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    
    def __init__(self, model_size="small", device="cpu", compute_type="int8"):
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏ '{model_size}'...")
        print(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, —Ç–∏–ø –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {compute_type}")
        
        start_time = time.time()
        
        try:
            self.model = WhisperModel(
                model_size_or_path=model_size,
                device=device,
                compute_type=compute_type,
                download_root=None,
                local_files_only=False
            )
            
            load_time = time.time() - start_time
            print(f"‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Whisper: {e}")
            print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω faster-whisper: pip install faster-whisper")
            raise
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_size = 8000
        
        # VAD –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.silence_threshold = 500
        self.silence_duration = 1.5
    
    def recognize_command(self, timeout=3, language="ru"):
        """
        –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –≥–æ–ª–æ—Å–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        ‚úÖ –ë–ï–ó –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ - –Ω–∞–ø—Ä—è–º—É—é –≤ Whisper
        """
        print(f"üé§ –°–ª—É—à–∞—é –∫–æ–º–∞–Ω–¥—É (—Ç–∞–π–º–∞—É—Ç: {timeout} —Å–µ–∫)...")
        
        try:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ –≤ numpy array
            audio_array = self._record_audio_with_vad(timeout)
            
            if audio_array is None or len(audio_array) == 0:
                print("‚ö†Ô∏è –ê—É–¥–∏–æ –Ω–µ –∑–∞–ø–∏—Å–∞–Ω–æ")
                return None
            
            # ‚úÖ –ü–†–Ø–ú–ê–Ø –ü–ï–†–ï–î–ê–ß–ê –≤ Whisper (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª)
            result_text = self._transcribe_audio_direct(audio_array, language)
            
            return result_text
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None
    
    def _record_audio_with_vad(self, timeout):
        """
        –ó–∞–ø–∏—Å—å —Å Voice Activity Detection
        ‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç numpy array –≤–º–µ—Å—Ç–æ WAV —Ñ–∞–π–ª–∞
        """
        audio = pyaudio.PyAudio()
        stream = None
        
        try:
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
            
            print("üî¥ –ó–∞–ø–∏—Å—å... (–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏ —Ç–∏—à–∏–Ω–µ)")
            frames = []
            
            silence_chunks_threshold = int(
                (self.silence_duration * self.sample_rate) / self.chunk_size
            )
            consecutive_silence = 0
            max_chunks = int(self.sample_rate / self.chunk_size * timeout)
            
            for i in range(max_chunks):
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                frames.append(data)
                
                # –ê–Ω–∞–ª–∏–∑ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
                audio_chunk = np.frombuffer(data, dtype=np.int16)
                volume = np.abs(audio_chunk).mean()
                
                if volume < self.silence_threshold:
                    consecutive_silence += 1
                else:
                    consecutive_silence = 0
                
                # –†–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥ –ø—Ä–∏ —Ç–∏—à–∏–Ω–µ
                if consecutive_silence >= silence_chunks_threshold and len(frames) > 5:
                    print(f"‚èπÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ç–∏—à–∏–Ω–∞ ({self.silence_duration} —Å–µ–∫)")
                    break
            else:
                print("‚èπÔ∏è –¢–∞–π–º–∞—É—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç")
            
            # ‚úÖ –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø: bytes ‚Üí numpy array ‚Üí float32 (—Ñ–æ—Ä–º–∞—Ç Whisper)
            audio_bytes = b''.join(frames)
            audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: int16 [-32768, 32767] ‚Üí float32 [-1.0, 1.0]
            audio_float32 = audio_int16.astype(np.float32) / 32768.0
            
            return audio_float32
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ: {e}")
            return None
            
        finally:
            if stream:
                stream.stop_stream()
                stream.close()
            audio.terminate()
    
    def _transcribe_audio_direct(self, audio_array, language):
        """
        ‚úÖ –ù–û–í–´–ô –ú–ï–¢–û–î: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑ numpy array (–±–µ–∑ —Ñ–∞–π–ª–æ–≤)
        
        Args:
            audio_array (np.ndarray): –ê—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ float32
            language (str): –ö–æ–¥ —è–∑—ã–∫–∞ –∏–ª–∏ None
        
        Returns:
            str: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        print("üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Whisper...")
        
        start_time = time.time()
        
        try:
            # ‚úÖ –ü–†–Ø–ú–ê–Ø –ü–ï–†–ï–î–ê–ß–ê numpy array –≤ Whisper
            segments, info = self.model.transcribe(
                audio_array,  # ‚Üê –í–º–µ—Å—Ç–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –ø–µ—Ä–µ–¥–∞—ë–º –º–∞—Å—Å–∏–≤!
                language=language,
                task="transcribe",
                
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                beam_size=1,
                best_of=1,
                
                # VAD –≤ Whisper
                vad_filter=True,
                vad_parameters=dict(
                    threshold=0.5,
                    min_speech_duration_ms=250,
                    min_silence_duration_ms=500
                ),
                
                temperature=0.0,
                condition_on_previous_text=False,
                word_timestamps=False
            )
            
            result_text = " ".join([segment.text.strip() for segment in segments])
            
            elapsed_time = time.time() - start_time
            
            if result_text:
                print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∑–∞ {elapsed_time:.2f} —Å–µ–∫: '{result_text}'")
                print(f"   –Ø–∑—ã–∫: {info.language} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {info.language_probability:.2%})")
            else:
                print(f"‚ö†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω—è–ª–∞ {elapsed_time:.2f} —Å–µ–∫)")
            
            return result_text if result_text else None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
            return None
    
    def listen_for_text(self, timeout=10):
        """
        –°–ª—É—à–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞ (—Ç–æ–ª—å–∫–æ ru/en)
        ‚úÖ –û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ - –±—ã—Å—Ç—Ä–µ–µ
        """
        print(f"üé§ –ñ–¥—É –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞ (–º–∞–∫—Å. {timeout} —Å–µ–∫, –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏ —Ç–∏—à–∏–Ω–µ)...")
        
        try:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            audio_array = self._record_audio_with_vad(timeout)
            
            if audio_array is None or len(audio_array) == 0:
                print("‚ö†Ô∏è –ê—É–¥–∏–æ –Ω–µ –∑–∞–ø–∏—Å–∞–Ω–æ")
                return None
            
            # ‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞
            print("üß† –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Whisper...")
            start_time = time.time()
            
            segments, info = self.model.transcribe(
                audio_array,
                language=None,  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                task="transcribe",
                beam_size=1,
                best_of=1,
                vad_filter=True,
                vad_parameters=dict(
                    threshold=0.5,
                    min_speech_duration_ms=250,
                    min_silence_duration_ms=500
                ),
                temperature=0.0,
                condition_on_previous_text=False,
                word_timestamps=False
            )
            
            result_text = " ".join([segment.text.strip() for segment in segments])
            elapsed_time = time.time() - start_time
            
            detected_lang = info.language
            confidence = info.language_probability
            
            # ‚úÖ –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ —è–∑—ã–∫ –ù–ï ru/en ‚Üí –ø–µ—Ä–µ—Å–ø—Ä–∞—à–∏–≤–∞–µ–º
            if detected_lang not in ['ru', 'en']:
                print(f"‚ö†Ô∏è –û–ø—Ä–µ–¥–µ–ª—ë–Ω –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —è–∑—ã–∫: {detected_lang} ({confidence:.2%})")
                print(f"   –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result_text}'")
                print(f"   –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è ru vs en...")
                
                # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º –∫–∞–∫ –†–£–°–°–ö–ò–ô
                segments_ru, info_ru = self.model.transcribe(
                    audio_array,
                    language='ru',
                    task="transcribe",
                    beam_size=1,
                    best_of=1,
                    vad_filter=True,
                    temperature=0.0,
                    condition_on_previous_text=False,
                    word_timestamps=False
                )
                text_ru = " ".join([segment.text.strip() for segment in segments_ru])
                confidence_ru = info_ru.language_probability
                
                # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º –∫–∞–∫ –ê–ù–ì–õ–ò–ô–°–ö–ò–ô
                segments_en, info_en = self.model.transcribe(
                    audio_array,
                    language='en',
                    task="transcribe",
                    beam_size=1,
                    best_of=1,
                    vad_filter=True,
                    temperature=0.0,
                    condition_on_previous_text=False,
                    word_timestamps=False
                )
                text_en = " ".join([segment.text.strip() for segment in segments_en])
                confidence_en = info_en.language_probability
                
                # –í—ã–±–∏—Ä–∞–µ–º —è–∑—ã–∫ —Å –ë–û–õ–¨–®–ï–ô —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                print(f"   üìä –†—É—Å—Å–∫–∏–π: '{text_ru}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence_ru:.2%})")
                print(f"   üìä –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: '{text_en}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence_en:.2%})")
                
                if confidence_ru > confidence_en:
                    result_text = text_ru
                    print(f"   ‚úÖ –í—ã–±—Ä–∞–Ω —Ä—É—Å—Å–∫–∏–π (–≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                else:
                    result_text = text_en
                    print(f"   ‚úÖ –í—ã–±—Ä–∞–Ω –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (–≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
            else:
                # –Ø–∑—ã–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
                print(f"üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∑–∞ {elapsed_time:.2f} —Å–µ–∫: '{result_text}'")
                print(f"   –Ø–∑—ã–∫: {detected_lang} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})")
            
            return result_text if result_text else None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None



# ============================================
# Utility —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
# ============================================

def test_whisper_basic():
    """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
    print("\n" + "="*50)
    print("–¢–ï–°–¢: –ë–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ")
    print("="*50 + "\n")
    
    recognizer = WhisperRecognizer(model_size="small")
    
    print("\nüé§ –°–∫–∞–∂–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ø—Ä–∏–≤–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä')...")
    result = recognizer.recognize_command(timeout=3)
    
    if result:
        print(f"\n‚úÖ –£–°–ü–ï–•! –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result}'")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å")


def test_whisper_music():
    """–¢–µ—Å—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π"""
    print("\n" + "="*50)
    print("–¢–ï–°–¢: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤")
    print("="*50 + "\n")
    
    recognizer = WhisperRecognizer(model_size="small")
    
    print("\nüé§ –°–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä: 'tveth Paramedic')...")
    result = recognizer.recognize_command(timeout=4, language=None)
    
    if result:
        print(f"\n‚úÖ –£–°–ü–ï–•! –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result}'")
        print(f"   (–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤)")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å")


if __name__ == "__main__":
    # –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç
    test_whisper_basic()
    
    # –¢–µ—Å—Ç –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
    # test_whisper_music()
